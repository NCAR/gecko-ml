{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MaxAbsScaler, MinMaxScaler, QuantileTransformer\n",
    "from sklearn.model_selection import GroupShuffleSplit, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from os.path import join, exists\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import traceback\n",
    "import random\n",
    "import pickle\n",
    "import glob\n",
    "import json\n",
    "import yaml\n",
    "import time\n",
    "import copy\n",
    "import re\n",
    "import os\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "from holodecml.vae.checkpointer import *\n",
    "from holodecml.vae.optimizers import *\n",
    "from holodecml.vae.tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import *\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to use device cuda:0\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device(torch.cuda.current_device()) if is_cuda else torch.device(\"cpu\")\n",
    "\n",
    "if is_cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print(f'Preparing to use device {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/9_29/exp1/config.yml\") as config_file:\n",
    "    config = yaml.load(config_file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadGeckoPandasExperiment:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 data_path, \n",
    "                 input_cols, \n",
    "                 output_cols, \n",
    "                 experiment_subset = False,\n",
    "                 x_data = False,\n",
    "                 y_data = False,\n",
    "                 shuffle = True):\n",
    "        \n",
    "        self.data_path = data_path\n",
    "        self.input_cols = input_cols\n",
    "        self.output_cols = output_cols  \n",
    "        self.experiment_subset = experiment_subset\n",
    "        self.x = x_data\n",
    "        self.y = y_data\n",
    "        \n",
    "        self.shuffle = shuffle\n",
    "        self.load()\n",
    "    \n",
    "    def load(self):\n",
    "        if not isinstance(self.x, pd.DataFrame):\n",
    "            self.x = pd.read_csv(os.path.join(self.data_path, \"row_data_in.csv\"))\n",
    "            self.x[\"id\"] = self.x[\"id\"].apply(lambda x: int(x.strip(\"Exp\")))\n",
    "        if not isinstance(self.y, pd.DataFrame):\n",
    "            self.y = pd.read_csv(os.path.join(self.data_path, \"row_data_out.csv\"))\n",
    "            self.y[\"id\"] = self.y[\"id\"].apply(lambda x: int(x.strip(\"Exp\")))\n",
    "        \n",
    "        drop_cols = [\"index\", \"indexer\"]\n",
    "        for df in [self.x, self.y]:\n",
    "            keep_cols = [x for x in df.columns if x not in drop_cols]\n",
    "            df = df[keep_cols].copy()\n",
    "            \n",
    "        if self.experiment_subset:\n",
    "            cond1 = self.x['id'].isin(self.experiment_subset)\n",
    "            cond2 = self.y['id'].isin(self.experiment_subset)\n",
    "            self.x = self.x[cond1].copy()\n",
    "            self.y = self.y[cond2].copy()\n",
    "        \n",
    "        self.x_dict = {\n",
    "            experiment: group for (experiment, group) in self.x.groupby([\"id\"])\n",
    "        }\n",
    "        self.y_dict = {\n",
    "            experiment: group for (experiment, group) in self.y.groupby([\"id\"])\n",
    "        }\n",
    "        self.w_dict = {\n",
    "            experiment: group[\"weight\"] for (experiment, group) in self.y_dict.items()\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(self.data_path, \"scalers.pkl\"), \"rb\") as fid:\n",
    "            self.scaler_x, self.scaler_y = pickle.load(fid)\n",
    "               \n",
    "        self.x_dict = {\n",
    "            experiment: self.scaler_x.transform(\n",
    "                group[self.input_cols].drop(['Time [s]', 'id'], axis=1)\n",
    "            ) \n",
    "            for (experiment, group) in self.x_dict.items()\n",
    "        }\n",
    "        self.y_dict = {\n",
    "            experiment: self.scaler_y.transform(\n",
    "                group[self.output_cols].drop(['Time [s]', 'id'], axis=1)\n",
    "            ) \n",
    "            for (experiment, group) in self.y_dict.items()\n",
    "        }\n",
    "        \n",
    "        self.indices = list(self.y_dict.keys())\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.indices[idx]\n",
    "        X = self.x_dict[idx]\n",
    "        Y = self.y_dict[idx]\n",
    "        W = self.w_dict[idx]\n",
    "        \n",
    "        for (x, y, w) in zip(X, Y, W):\n",
    "            x_data = torch.from_numpy(x.astype(np.float32))\n",
    "            y_data = torch.from_numpy(y.astype(np.float32))\n",
    "            w_data = torch.from_numpy(np.array([w]))\n",
    "            yield (x_data, y_data, w_data)\n",
    "            \n",
    "        self.processed += 1\n",
    "        if (self.processed == self.__len__()):\n",
    "            self.on_epoch_end()\n",
    "            \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.processed = 0\n",
    "        if self.shuffle == True:\n",
    "            random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the train, test, val splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_data = LoadGeckoPandasExperiment(\n",
    "    \"clustered/row_data\", \n",
    "    config[\"data\"][\"input_cols\"],\n",
    "    config[\"data\"][\"output_cols\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"clustered/experiment_data/experiment_train_test_val_splits.pkl\"\n",
    "with open(fn, \"rb\") as fid:\n",
    "    train, valid, test = pickle.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_set = LoadGeckoPandasExperiment(\n",
    "    \"clustered/row_data\", \n",
    "    config[\"data\"][\"input_cols\"],\n",
    "    config[\"data\"][\"output_cols\"],\n",
    "    experiment_subset = train,\n",
    "    x_data = experiment_data.x,\n",
    "    y_data = experiment_data.y,\n",
    "    shuffle = config[\"data\"][\"shuffle\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data_set = LoadGeckoPandasExperiment(\n",
    "    \"clustered/row_data\", \n",
    "    config[\"data\"][\"input_cols\"],\n",
    "    config[\"data\"][\"output_cols\"],\n",
    "    experiment_subset = valid,\n",
    "    x_data = experiment_data.x,\n",
    "    y_data = experiment_data.y,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_set = LoadGeckoPandasExperiment(\n",
    "    \"clustered/row_data\", \n",
    "    config[\"data\"][\"input_cols\"],\n",
    "    config[\"data\"][\"output_cols\"],\n",
    "    experiment_subset = test,\n",
    "    x_data = experiment_data.x,\n",
    "    y_data = experiment_data.y,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logging.info(f\"Loading training data iterator using {config['iterator']['num_workers']} workers\")\n",
    "    \n",
    "# train_dataloader = DataLoader(\n",
    "#     train_data_set,\n",
    "#     **config[\"iterator\"]\n",
    "# )\n",
    "\n",
    "# valid_dataloader = DataLoader(\n",
    "#     valid_data_set,\n",
    "#     **config[\"iterator\"]\n",
    "# )\n",
    "\n",
    "# test_dataloader = DataLoader(\n",
    "#     test_data_set,\n",
    "#     **config[\"iterator\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 input_size, \n",
    "                 output_size, \n",
    "                 hidden_dims = [100, 50], \n",
    "                 dropouts = [0.2, 0.2]):\n",
    "        \n",
    "        super(DenseNet, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        #self.embedding = nn.Embedding(train_data_set.num_timesteps, 16)\n",
    "        \n",
    "        self.model = [\n",
    "            nn.Linear(input_size, hidden_dims[0]),\n",
    "            #nn.BatchNorm1d(num_features=hidden_dims[0]),\n",
    "            nn.LeakyReLU()\n",
    "        ]\n",
    "        if len(hidden_dims) > 1:\n",
    "            if dropouts[0] > 0.0:\n",
    "                self.model.append(nn.Dropout(dropouts[0]))\n",
    "            for i in range(len(hidden_dims)-1):\n",
    "                self.model.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n",
    "                #self.model.append(nn.BatchNorm1d(num_features=hidden_dims[i+1]))\n",
    "                self.model.append(nn.LeakyReLU())\n",
    "                if dropouts[i+1] > 0.0:\n",
    "                    self.model.append(nn.Dropout(dropouts[i+1]))\n",
    "        self.model.append(nn.Linear(hidden_dims[-1], output_size))\n",
    "        self.model.append(nn.Sigmoid())\n",
    "        self.model = nn.Sequential(*self.model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x1, x2 = x\n",
    "        #x1 = self.embedding(x1)\n",
    "        #x = torch.cat([x1, x2], 1)\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseNet(**config[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=35, out_features=10000, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=10000, out_features=29, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict = torch.load(\"results/9_29/row1/best.pt\", \n",
    "                        map_location=lambda storage, loc: storage)\n",
    "\n",
    "model.load_state_dict(model_dict[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_cuda:\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = LookaheadDiffGrad(model.parameters(),\n",
    "                              lr=config[\"optimizer\"][\"lr\"],\n",
    "                              weight_decay=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    \n",
    "    def __init__(self, alpha = 1.0):\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def WMSE(self, y_true, y_pred, weights = []):   \n",
    "        mse = torch.mean(weights * (y_true - y_pred) ** 2)\n",
    "        return mse\n",
    "        \n",
    "    def train(self, y_true, y_pred, weights):   \n",
    "        y_true = torch.stack(y_true).permute(1,0,2)\n",
    "        y_pred = torch.stack(y_pred).permute(1,0,2)\n",
    "        weights = torch.stack(weights).permute(1,0)\n",
    "        \n",
    "        y_true_precursor = y_true[:, :, 0]\n",
    "        y_pred_precursor = y_pred[:, :, 0]\n",
    "\n",
    "        y_true_gas = y_true[:, :, 1:15]\n",
    "        y_pred_gas = y_pred[:, :, 1:15]\n",
    "\n",
    "        y_true_aero = y_true[:, :, 15:]\n",
    "        y_pred_aero = y_pred[:, :, 15:]\n",
    "\n",
    "        mse_precursor = self.WMSE(\n",
    "            y_true_precursor, \n",
    "            y_pred_precursor, \n",
    "            weights\n",
    "        )\n",
    "        mse_gas = self.WMSE(\n",
    "            y_true_gas.permute(1, 0, 2), \n",
    "            y_pred_gas.permute(1, 0, 2),\n",
    "            weights.permute(1, 0)\n",
    "        )\n",
    "        mse_aero = self.WMSE(\n",
    "            y_true_aero.permute(1, 0, 2), \n",
    "            y_pred_aero.permute(1, 0, 2), \n",
    "            weights.permute(1, 0)\n",
    "        )\n",
    "        mse = mse_precursor + mse_gas + mse_aero\n",
    "\n",
    "        kld_gas = nn.KLDivLoss()(\n",
    "            F.log_softmax(y_pred_gas),\n",
    "            F.softmax(y_true_gas)\n",
    "        )\n",
    "        kld_aero = nn.KLDivLoss()(\n",
    "            F.log_softmax(y_pred_aero),\n",
    "            F.softmax(y_true_aero)\n",
    "        )\n",
    "        return mse + self.alpha * (kld_gas + kld_aero)\n",
    "    \n",
    "    def test(self, y_true, y_pred):  \n",
    "        y_true = torch.stack(y_true).permute(1,0,2)\n",
    "        y_pred = torch.stack(y_pred).permute(1,0,2)\n",
    "        \n",
    "        y_true_precursor = y_true[:, :, 0]\n",
    "        y_pred_precursor = y_pred[:, :, 0]\n",
    "\n",
    "        y_true_gas = y_true[:, :, 1:15]\n",
    "        y_pred_gas = y_pred[:, :, 1:15]\n",
    "\n",
    "        y_true_aero = y_true[:, :, 15:]\n",
    "        y_pred_aero = y_pred[:, :, 15:]\n",
    "\n",
    "        mse_precursor = nn.MSELoss()(y_true_precursor, y_pred_precursor)\n",
    "        mse_gas = nn.MSELoss()(y_true_gas, y_pred_gas)\n",
    "        mse_aero = nn.MSELoss()(y_true_aero, y_pred_aero)\n",
    "        mse = mse_precursor + mse_gas + mse_aero\n",
    "\n",
    "        kld_gas = nn.KLDivLoss()(\n",
    "            F.log_softmax(y_pred_gas),\n",
    "            F.softmax(y_true_gas)\n",
    "        )\n",
    "        kld_aero = nn.KLDivLoss()(\n",
    "            F.log_softmax(y_pred_aero),\n",
    "            F.softmax(y_true_aero)\n",
    "        )\n",
    "        return mse + self.alpha * (kld_gas + kld_aero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Measure allocated memory after the call\n",
    "# torch.cuda.synchronize()\n",
    "# end_max_memory = torch.cuda.max_memory_allocated() / 1024**2\n",
    "# end_memory = torch.cuda.memory_allocated() / 1024**2\n",
    "\n",
    "class BaseTrainer:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model, \n",
    "                 optimizer,\n",
    "                 train_gen, \n",
    "                 valid_gen, \n",
    "                 dataloader, \n",
    "                 valid_dataloader,\n",
    "                 start_epoch = 0,\n",
    "                 epochs = 100,\n",
    "                 timesteps = 1439,\n",
    "                 window_size = 10,\n",
    "                 teacher_force = True,\n",
    "                 gamma = 0.5,\n",
    "                 device = \"cpu\",\n",
    "                 clip = 1.0,\n",
    "                 path_save = \"./\"):\n",
    "        \n",
    "        self.model = model\n",
    "        self.outsize = model.output_size\n",
    "        self.optimizer = optimizer\n",
    "        self.train_gen = train_gen\n",
    "        self.valid_gen = valid_gen\n",
    "        self.dataloader = dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.batch_size = 1 #dataloader.batch_size\n",
    "        self.path_save = path_save\n",
    "        self.device = device\n",
    "        \n",
    "        self.start_epoch = start_epoch \n",
    "        self.epochs = epochs\n",
    "        self.window_size = window_size\n",
    "        \n",
    "        self.teacher_force = teacher_force\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        #self.criterion = nn.MSELoss()\n",
    "        \n",
    "        timesteps = timesteps\n",
    "        self.time_range = list(range(timesteps))\n",
    "                \n",
    "        # Gradient clipping through hook registration\n",
    "        for p in self.model.parameters():\n",
    "            p.register_hook(lambda grad: torch.clamp(grad, -clip, clip))\n",
    "        logger.info(f\"Clipping gradients to range [-{clip}, {clip}]\")\n",
    "        \n",
    "        # Create the save directory if it does not exist\n",
    "        try:\n",
    "            os.makedirs(path_save)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        self.criterion = Loss()\n",
    "        \n",
    "    def train_one_epoch(self, epoch, steps = 100):\n",
    "        \n",
    "        self.model.train()\n",
    "        batches_per_epoch = int(np.ceil(self.train_gen.__len__() / self.batch_size))\n",
    "        \n",
    "        if batches_per_epoch > steps:\n",
    "            batches_per_epoch = steps\n",
    "            \n",
    "        experiments = range(len(self.train_gen.experiment_subset))        \n",
    "        batch_group_generator = tqdm(\n",
    "            enumerate(experiments),\n",
    "            total=batches_per_epoch, \n",
    "            leave=True\n",
    "        )\n",
    "    \n",
    "        cost = self.tf_annealer(epoch)\n",
    "        epoch_losses = {\"loss\": []}\n",
    "        \n",
    "        #model_clone = copy.deepcopy(self.model)\n",
    "        for batch_idx, exp in batch_group_generator:\n",
    "            y_true, y_pred, weights = [], [], []\n",
    "            for i, (x,y,w) in enumerate(self.train_gen.__getitem__(exp)):\n",
    "                x = x.view(1, x.size(0)).to(device)\n",
    "                y = y.view(1, y.size(0)).to(device)\n",
    "                w = w.to(device)\n",
    "                \n",
    "                idx = [bn for bn in range(x.size(0)) if cost < random.random()]\n",
    "                \n",
    "                x = x.clone()\n",
    "                if not self.teacher_force and (i > 0): # Never force\n",
    "                    x[:, :self.outsize] = next_x.detach() # Always use predicted answer\n",
    "                elif len(idx) and (i > 0): # Conditional force\n",
    "                    x[idx, :self.outsize] = next_x[idx].detach() # Substitute in some predicted answers \n",
    "                else: # Always force\n",
    "                    pass \n",
    "                                  \n",
    "                next_x = self.model(x)\n",
    "                y_true.append(y)\n",
    "                y_pred.append(next_x)\n",
    "                weights.append(w)\n",
    "                \n",
    "            loss = self.criterion.train(y_true, y_pred, weights)  \n",
    "            epoch_losses[\"loss\"].append(loss.item())\n",
    "            \n",
    "            # backprop after experiment\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # update tqdm\n",
    "            to_print = \"Epoch {} training loss: {:.3f}\".format(\n",
    "                epoch, np.mean(epoch_losses[\"loss\"])\n",
    "            )\n",
    "            batch_group_generator.set_description(to_print)\n",
    "            batch_group_generator.update()\n",
    "            \n",
    "            if batch_idx > 0 and (batch_idx % steps) == 0:\n",
    "                break\n",
    "        #self.model = model_clone\n",
    "        return np.mean(epoch_losses[\"loss\"])\n",
    "            \n",
    "    def test(self, epoch):\n",
    "\n",
    "        self.model.eval()\n",
    "        batches_per_epoch = int(np.ceil(self.valid_gen.__len__() / self.batch_size))\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            batch_group_generator = tqdm(\n",
    "                enumerate(range(len(self.valid_gen.experiment_subset))),\n",
    "                total=len(self.valid_gen.experiment_subset), \n",
    "                leave=True\n",
    "            )\n",
    "            \n",
    "            epoch_losses = {\"loss\": []}\n",
    "            for batch_idx, exp in batch_group_generator:\n",
    "                y_true, y_pred, weights = [], [], []\n",
    "                for i, (x,y,w) in enumerate(self.valid_gen.__getitem__(exp)):\n",
    "                    x = x.view(1, x.size(0)).to(device)\n",
    "                    y = y.view(1, y.size(0)).to(device)\n",
    "                    if i > 0:\n",
    "                        x[:, :self.outsize] = next_x\n",
    "                    next_x = self.model(x)\n",
    "                    y_true.append(y)\n",
    "                    y_pred.append(next_x)\n",
    "                    \n",
    "                loss = self.criterion.test(y_true, y_pred)   \n",
    "                epoch_losses[\"loss\"].append(loss.item())\n",
    "                \n",
    "                # update tqdm\n",
    "                to_print = \"Epoch {} validation loss: {:.3f}\".format(\n",
    "                    epoch, np.mean(epoch_losses[\"loss\"])\n",
    "                )\n",
    "                batch_group_generator.set_description(to_print)\n",
    "                batch_group_generator.update()\n",
    "            \n",
    "        return np.mean(epoch_losses[\"loss\"]) \n",
    "    \n",
    "    \n",
    "    def train(self,\n",
    "              scheduler,\n",
    "              early_stopping,\n",
    "              metrics_logger):\n",
    "        \n",
    "        logger.info(\n",
    "            f\"Training the model for up to {self.epochs} epochs starting at epoch {self.start_epoch}\"\n",
    "        )\n",
    "        \n",
    "        flag = isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau)\n",
    "        \n",
    "        for epoch in range(self.start_epoch, self.epochs):\n",
    "            train_loss = self.train_one_epoch(epoch)\n",
    "            test_loss = self.test(epoch)\n",
    "\n",
    "            scheduler.step(test_loss if flag else epoch)\n",
    "            early_stopping(epoch, test_loss, self.model, self.optimizer)\n",
    "\n",
    "            # Write results to the callback logger \n",
    "            result = {\n",
    "                \"epoch\": epoch,\n",
    "                \"train_loss\": train_loss,\n",
    "                \"valid_loss\": test_loss,\n",
    "                \"lr\": early_stopping.print_learning_rate(self.optimizer),\n",
    "                \"teacher_forcing_score\": self.tf_annealer(epoch) if self.teacher_force else 1.0\n",
    "            }\n",
    "            metrics_logger.update(result)\n",
    "\n",
    "            if early_stopping.early_stop:\n",
    "                logger.info(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "    def tf_annealer(self, epoch):\n",
    "        return 1.0 * self.gamma ** epoch # 1/(1 + self.decay * epoch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = BaseTrainer(\n",
    "    model, \n",
    "    optimizer,\n",
    "    train_data_set, \n",
    "    valid_data_set, \n",
    "    None, \n",
    "    None,\n",
    "    device = device,\n",
    "    **config[\"trainer\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LR annealing scheduler \n",
    "if \"ReduceLROnPlateau\" in config[\"callbacks\"]:\n",
    "    schedule_config = config[\"callbacks\"][\"ReduceLROnPlateau\"]\n",
    "    scheduler = ReduceLROnPlateau(trainer.optimizer, **schedule_config)\n",
    "    #logging.info(\n",
    "    #    f\"Loaded ReduceLROnPlateau learning rate annealer with patience {schedule_config['patience']}\"\n",
    "    #)\n",
    "elif \"ExponentialLR\" in config[\"callbacks\"]:\n",
    "    schedule_config = config[\"callbacks\"][\"ExponentialLR\"]\n",
    "    scheduler = ExponentialLR(trainer.optimizer, **schedule_config)\n",
    "    #logging.info(\n",
    "    #    f\"Loaded ExponentialLR learning rate annealer with reduce factor {schedule_config['gamma']}\"\n",
    "    #)\n",
    "\n",
    "# Early stopping\n",
    "checkpoint_config = config[\"callbacks\"][\"EarlyStopping\"]\n",
    "early_stopping = EarlyStopping(**checkpoint_config)\n",
    "\n",
    "# Write metrics to csv each epoch\n",
    "metrics_logger = MetricsLogger(**config[\"callbacks\"][\"MetricsLogger\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.autograd.set_detect_anomaly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 training loss: 0.001: 100%|██████████| 100/100 [01:09<00:00,  1.45it/s]\n",
      "Epoch 0 validation loss: 0.467: 100%|██████████| 201/201 [01:05<00:00,  3.05it/s]\n",
      "Epoch 1 training loss: 0.001: 100%|██████████| 100/100 [01:09<00:00,  1.43it/s]\n",
      "Epoch 1 validation loss: 0.421: 100%|██████████| 201/201 [01:05<00:00,  3.08it/s]\n",
      "Epoch 2 training loss: 0.001: 100%|██████████| 100/100 [01:06<00:00,  1.50it/s]\n",
      "Epoch 2 validation loss: 0.375: 100%|██████████| 201/201 [01:05<00:00,  3.07it/s]\n",
      "Epoch 3 training loss: 0.001: 100%|██████████| 100/100 [01:06<00:00,  1.50it/s]\n",
      "Epoch 3 validation loss: 0.365: 100%|██████████| 201/201 [01:05<00:00,  3.08it/s]\n",
      "Epoch 4 training loss: 0.001: 100%|██████████| 100/100 [01:07<00:00,  1.48it/s]\n",
      "Epoch 4 validation loss: 0.353: 100%|██████████| 201/201 [01:04<00:00,  3.10it/s]\n",
      "Epoch 5 training loss: 0.002: 100%|██████████| 100/100 [01:06<00:00,  1.50it/s]\n",
      "Epoch 5 validation loss: 0.348: 100%|██████████| 201/201 [01:05<00:00,  3.06it/s]\n",
      "Epoch 6 training loss: 0.002: 100%|██████████| 100/100 [01:07<00:00,  1.49it/s]\n",
      "Epoch 6 validation loss: 0.334: 100%|██████████| 201/201 [01:04<00:00,  3.13it/s]\n",
      "Epoch 7 training loss: 0.002: 100%|██████████| 100/100 [01:06<00:00,  1.51it/s]\n",
      "Epoch 7 validation loss: 0.312: 100%|██████████| 201/201 [01:03<00:00,  3.14it/s]\n",
      "Epoch 8 training loss: 0.002: 100%|██████████| 100/100 [01:06<00:00,  1.51it/s]\n",
      "Epoch 8 validation loss: 0.298: 100%|██████████| 201/201 [01:03<00:00,  3.15it/s]\n",
      "Epoch 9 training loss: 0.002: 100%|██████████| 100/100 [01:13<00:00,  1.37it/s]\n",
      "Epoch 9 validation loss: 0.290: 100%|██████████| 201/201 [01:05<00:00,  3.09it/s]\n",
      "Epoch 10 training loss: 0.003: 100%|██████████| 100/100 [01:09<00:00,  1.44it/s]\n",
      "Epoch 10 validation loss: 0.280: 100%|██████████| 201/201 [01:04<00:00,  3.13it/s]\n",
      "Epoch 11 training loss: 0.003: 100%|██████████| 100/100 [01:08<00:00,  1.46it/s]\n",
      "Epoch 11 validation loss: 0.278: 100%|██████████| 201/201 [01:09<00:00,  2.87it/s]\n",
      "Epoch 12 training loss: 0.003: 100%|██████████| 100/100 [01:06<00:00,  1.50it/s]\n",
      "Epoch 12 validation loss: 0.266: 100%|██████████| 201/201 [01:04<00:00,  3.12it/s]\n",
      "Epoch 13 training loss: 0.003: 100%|██████████| 100/100 [01:06<00:00,  1.50it/s]\n",
      "Epoch 13 validation loss: 0.260: 100%|██████████| 201/201 [01:05<00:00,  3.06it/s]\n",
      "Epoch 14 training loss: 0.004: 100%|██████████| 100/100 [01:06<00:00,  1.50it/s]\n",
      "Epoch 14 validation loss: 0.260: 100%|██████████| 201/201 [01:03<00:00,  3.14it/s]\n",
      "Epoch 15 training loss: 0.004: 100%|██████████| 100/100 [01:06<00:00,  1.50it/s]\n",
      "Epoch 15 validation loss: 0.284: 100%|██████████| 201/201 [01:03<00:00,  3.15it/s]\n",
      "Epoch 16 training loss: 0.004: 100%|██████████| 100/100 [01:06<00:00,  1.50it/s]\n",
      "Epoch 16 validation loss: 0.288: 100%|██████████| 201/201 [01:05<00:00,  3.08it/s]\n",
      "Epoch 17 training loss: 0.005: 100%|██████████| 100/100 [01:06<00:00,  1.51it/s]\n",
      "Epoch 17 validation loss: 0.291: 100%|██████████| 201/201 [01:04<00:00,  3.12it/s]\n",
      "Epoch 18 training loss: 0.005: 100%|██████████| 100/100 [01:11<00:00,  1.40it/s]\n",
      "Epoch 18 validation loss: 0.291: 100%|██████████| 201/201 [01:04<00:00,  3.13it/s]\n",
      "Epoch 19 training loss: 0.005: 100%|██████████| 100/100 [01:08<00:00,  1.46it/s]\n",
      "Epoch 19 validation loss: 0.290: 100%|██████████| 201/201 [01:03<00:00,  3.15it/s]\n",
      "Epoch 20 training loss: 0.005: 100%|██████████| 100/100 [01:11<00:00,  1.39it/s]\n",
      "Epoch 20 validation loss: 0.290: 100%|██████████| 201/201 [01:03<00:00,  3.17it/s]\n",
      "Epoch 21 training loss: 0.006: 100%|██████████| 100/100 [01:08<00:00,  1.45it/s]\n",
      "Epoch 21 validation loss: 0.291: 100%|██████████| 201/201 [01:04<00:00,  3.09it/s]\n",
      "Epoch 22 training loss: 0.006: 100%|██████████| 100/100 [01:09<00:00,  1.43it/s]\n",
      "Epoch 22 validation loss: 0.291: 100%|██████████| 201/201 [01:05<00:00,  3.07it/s]\n",
      "Epoch 23 training loss: 0.006: 100%|██████████| 100/100 [01:09<00:00,  1.45it/s]\n",
      "Epoch 23 validation loss: 0.292: 100%|██████████| 201/201 [01:04<00:00,  3.12it/s]\n",
      "Epoch 24 training loss: 0.006: 100%|██████████| 100/100 [01:11<00:00,  1.39it/s]\n",
      "Epoch 24 validation loss: 0.291: 100%|██████████| 201/201 [01:03<00:00,  3.17it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.train(scheduler, early_stopping, metrics_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.read_csv(\"results/9_29/exp1/training_log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(f[\"epoch\"], f[\"train_loss\"])\n",
    "plt.semilogy(f[\"epoch\"], f[\"valid_loss\"])\n",
    "\n",
    "plt.xlabel(\"Epoch\", fontsize = 12)\n",
    "plt.ylabel(\"Loss\", fontsize = 12)\n",
    "\n",
    "plt.legend([\"train\", \"valid\"])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseNet(**config[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = torch.load(\"results/9_29/row1/best.pt\", \n",
    "                        map_location=lambda storage, loc: storage)\n",
    "model.load_state_dict(model_dict[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if is_cuda:\n",
    "#     model = model.to(device)\n",
    "device = \"cpu\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, y_pred, y_true = [], [], []\n",
    "\n",
    "for (x,y,w) in tqdm(valid_data_set.__getitem__(0)):\n",
    "    x = x.view(1, x.size(0)).to(device)\n",
    "    y = y.view(1, y.size(0)).to(device)\n",
    "    w = w.to(device)\n",
    "    \n",
    "    next_x = model(x)\n",
    "    y_pred.append(next_x)\n",
    "    y_true.append(y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, y_pred, y_true = [], [], []\n",
    "\n",
    "for k, (x,y,w) in tqdm(enumerate(valid_data_set.__getitem__(0))):\n",
    "    x = x.view(1, x.size(0)).to(device)\n",
    "    y = y.view(1, y.size(0)).to(device)\n",
    "    w = w.to(device)\n",
    "    \n",
    "    X = x\n",
    "    #if k == 0:\n",
    "    #    X = x\n",
    "    \n",
    "    next_x = model(X)\n",
    "    #loss.append(RMSELoss()(next_x, y[:,t]))\n",
    "    \n",
    "    y_pred.append(next_x)\n",
    "    y_true.append(y) \n",
    "    \n",
    "    #X[:, :model.output_size] = next_x\n",
    "    \n",
    "# #loss = torch.mean(torch.stack(loss))\n",
    "# preds = torch.stack(preds, axis = -1).permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantities(Y):\n",
    "    a, b, c = [], [], []\n",
    "    for y in Y:\n",
    "        y = y[0, :]\n",
    "        prec = y[0]\n",
    "        gas = y[1:15].sum(-1)/14\n",
    "        aero = y[15:].sum(-1)/14\n",
    "        a.append(prec.item())\n",
    "        b.append(gas.item())\n",
    "        c.append(aero.item())\n",
    "    return a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_pred, gas_pred, aero_pred = quantities(y_pred)\n",
    "prec_true, gas_true, aero_true = quantities(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(prec_pred)), prec_pred)\n",
    "plt.plot(range(len(prec_pred)), prec_true)\n",
    "\n",
    "plt.legend([\"Predicted\", \"True\"])\n",
    "\n",
    "plt.ylabel(\"Precursor/Gas/Aerosol\")\n",
    "plt.xlabel(\"Time steps\")\n",
    "\n",
    "plt.ylim([0.0, 1.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(prec_pred)), gas_pred)\n",
    "plt.plot(range(len(prec_pred)), gas_true)\n",
    "\n",
    "plt.legend([\"Predicted\", \"True\"])\n",
    "\n",
    "plt.ylabel(\"Precursor/Gas/Aerosol\")\n",
    "plt.xlabel(\"Time steps\")\n",
    "\n",
    "plt.ylim([0.0, 1.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(prec_pred)), aero_pred)\n",
    "plt.plot(range(len(prec_pred)), aero_true)\n",
    "\n",
    "plt.legend([\"Predicted\", \"True\"])\n",
    "\n",
    "plt.ylabel(\"Precursor/Gas/Aerosol\")\n",
    "plt.xlabel(\"Time steps\")\n",
    "\n",
    "plt.ylim([0.0, 1.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
