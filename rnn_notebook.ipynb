{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "import yaml\n",
    "import copy\n",
    "import pickle\n",
    "import logging\n",
    "import traceback\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "    \n",
    "from geckoml.models import DenseNeuralNetwork, GRUNet\n",
    "from geckoml.metrics import *\n",
    "from geckoml.data import *\n",
    "from geckoml.box import *\n",
    "\n",
    "from aimlutils.echo.src.base_objective import *\n",
    "import torch\n",
    "import tqdm.auto as tqdm\n",
    "\n",
    "sys.path.append(\"/glade/work/schreck/repos/holodec-ml/scripts/schreck/object\")\n",
    "from cosine_schedule import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the GPU\n",
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device(torch.cuda.current_device()) if is_cuda else torch.device(\"cpu\")\n",
    "if is_cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(5006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_timesteps = 1440\n",
    "\n",
    "starting_index = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_box_test(model, exps, num_timesteps, in_array, env_array, y_scaler, output_cols, out_val, stable_thresh = 1.0, starting_index = [0]):\n",
    "    \n",
    "    epoch_loss = []\n",
    "    box_loss_mae = []\n",
    "    loss_fn = mean_absolute_error\n",
    "    \n",
    "    for start_time in starting_index:\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # use initial condition @ t = 0 and get the first prediction\n",
    "            pred_array = np.empty((len(exps), 1439-start_time, 2))\n",
    "            h0 = model.init_hidden(torch.from_numpy(in_array[:, start_time, :]).float())\n",
    "            pred, h0 = model.predict(in_array[:, start_time, :], h0)\n",
    "            pred_array[:, 0, :] = pred\n",
    "            loss = loss_fn(in_array[:, start_time+1, 1:3], pred)\n",
    "            epoch_loss.append(loss)\n",
    "\n",
    "            # use the first prediction to get the next, and so on for num_timesteps\n",
    "            for k, i in enumerate(range(start_time + 1, num_timesteps)): \n",
    "                precursor = in_array[:, i, 0:1] \n",
    "                temperature = in_array[:, i, 3:4] \n",
    "                static_env = env_array[:, -5:]\n",
    "                new_input = np.block([precursor, pred, temperature, static_env])\n",
    "                pred, h0 = model.predict(new_input, h0)\n",
    "                pred_array[:, k+1, :] = pred\n",
    "                if i < (num_timesteps-1):\n",
    "                    loss = loss_fn(in_array[:, i+1, 1:3], pred)\n",
    "                    epoch_loss.append(loss)\n",
    "\n",
    "        # loop over the batch to fill up results dict\n",
    "        results_dict = {}\n",
    "        for k, exp in enumerate(exps):\n",
    "            results_dict[exp] = pd.DataFrame(y_scaler.inverse_transform(pred_array[k]), columns=output_cols[2:-1])\n",
    "            results_dict[exp]['id'] = exp\n",
    "            results_dict[exp]['Time [s]'] = out_val['Time [s]'].unique()[start_time:]\n",
    "            results_dict[exp] = results_dict[exp].reindex(output_cols, axis=1)\n",
    "\n",
    "        preds = pd.concat(results_dict.values())\n",
    "        truth = out_val.loc[out_val['id'].isin(exps)]\n",
    "        truth = truth.sort_values(['id', 'Time [s]']).reset_index(drop=True)\n",
    "        preds = preds.sort_values(['id', 'Time [s]']).reset_index(drop=True)\n",
    "\n",
    "        start_time_cond = truth['Time [s]'].isin(out_val['Time [s]'].unique()[start_time:])\n",
    "        truth = truth[start_time_cond]\n",
    "\n",
    "        # Check for instabilities\n",
    "        preds = preds.copy()\n",
    "        preds['Precursor [ug/m3]'] = 10**(preds['Precursor [ug/m3]'])\n",
    "        truth['Precursor [ug/m3]'] = 10**(truth['Precursor [ug/m3]'])\n",
    "        unstable = preds.groupby('id')['Precursor [ug/m3]'].apply(\n",
    "            lambda x: x[(x > stable_thresh) | (x < -stable_thresh)].any())\n",
    "        stable_exps = unstable[unstable == False].index\n",
    "        failed_exps = unstable[unstable == True].index\n",
    "        c1 = ~truth[\"id\"].isin(failed_exps)\n",
    "        c2 = ~preds[\"id\"].isin(failed_exps)\n",
    "        \n",
    "        if c2.sum() == 0:\n",
    "            box_mae = 1.0\n",
    "        else:\n",
    "            box_mae = mean_absolute_error(preds[c2].iloc[:, 2:-1], truth[c1].iloc[:, 2:-1])\n",
    "        box_loss_mae.append(box_mae)\n",
    "        \n",
    "    box_mae = np.mean(box_mae)\n",
    "    scaled_box_mae = np.mean(epoch_loss)\n",
    "    \n",
    "    return scaled_box_mae, box_mae, preds, truth #box_mae, scaled_box_mae, preds, truth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_box_train_one_epoch(model, optimizer, loss_fn, batch_size, \n",
    "                            exps, num_timesteps, in_array, env_array, hidden_weight = 1.0, starting_time = 0, grad_clip = 1.0):\n",
    "    \n",
    "    model.train()\n",
    "    device = model._device()\n",
    "\n",
    "    # Prepare the training dataset.\n",
    "    num_experiments = in_array.shape[0]\n",
    "    batches_per_epoch = int(np.ceil(num_experiments / batch_size))\n",
    "\n",
    "    batched_experiments = list(range(batches_per_epoch))\n",
    "    random.shuffle(batched_experiments)\n",
    "\n",
    "    train_epoch_loss = []\n",
    "        \n",
    "    updates = 0 \n",
    "    for j in batched_experiments:\n",
    "\n",
    "        _in_array = torch.from_numpy(in_array[j * batch_size: (j + 1) * batch_size]).to(device).float()\n",
    "        _env_array = torch.from_numpy(env_array[j * batch_size: (j + 1) * batch_size]).to(device).float()\n",
    "\n",
    "        # Use initial condition @ t = 0 and get the first prediction\n",
    "        # Clear gradient\n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        new_input = _in_array[:, starting_time, :]\n",
    "        h0 = model.init_hidden(new_input) \n",
    "        pred, h0 = model(new_input, h0)\n",
    "\n",
    "        # get loss for the predicted output\n",
    "        loss = loss_fn(_in_array[:, 1, 1:3], pred)\n",
    "\n",
    "        # get gradients w.r.t to parameters\n",
    "        loss.backward()\n",
    "        train_epoch_loss.append(loss.item())\n",
    "\n",
    "        # update parameters\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        #lr_scheduler.step(epoch + updates / (1439 * batches_per_epoch))\n",
    "        updates += 1\n",
    "\n",
    "        for i in range(starting_time + 1, num_timesteps-1):\n",
    "            # Use the last prediction to get the next prediction\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # static envs \n",
    "            precursor = _in_array[:, i, 0] \n",
    "            temperature = _in_array[:, i, 3:4] \n",
    "            static_env = _env_array[:, -5:]\n",
    "            new_input = torch.cat([torch.unsqueeze(precursor, 1), pred.detach(), temperature, static_env], 1)\n",
    "            \n",
    "        \n",
    "            \n",
    "            # predict hidden state\n",
    "            h0_pred = model.init_hidden(new_input.cpu())\n",
    "            # compute loss for the last hidden prediction\n",
    "            hidden_loss = loss_fn(h0.detach(), h0_pred)\n",
    "            \n",
    "            # predict next state with the GRU\n",
    "            pred, h0 = model(new_input, h0.detach())\n",
    "            loss = loss_fn(_in_array[:, 1, 1:3], pred)\n",
    "            \n",
    "            # combine losses\n",
    "            loss += hidden_weight * hidden_loss\n",
    "            \n",
    "            # compute the gradients\n",
    "            loss.backward()\n",
    "            train_epoch_loss.append(loss.item())\n",
    "\n",
    "            # update parameters\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            optimizer.step()\n",
    "            \n",
    "            #lr_scheduler.step(epoch + updates / (1439 * batches_per_epoch))\n",
    "            updates += 1\n",
    "\n",
    "    train_loss = np.mean(train_epoch_loss)\n",
    "    \n",
    "    return train_loss, model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/glade/work/keelyl/geckonew/gecko-ml/model.yml\") as config_file:\n",
    "        conf = yaml.load(config_file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {\"MinMaxScaler\": MinMaxScaler, \"StandardScaler\": StandardScaler}\n",
    "\n",
    "species =  conf['species'] # \"dodecane\"\n",
    "dir_path = conf['dir_path']\n",
    "summary_file = conf['summary_file']\n",
    "aggregate_bins = conf['aggregate_bins']\n",
    "bin_prefix = conf['bin_prefix']\n",
    "input_vars = conf['input_vars']\n",
    "output_vars = conf['output_vars']\n",
    "scaler_type = \"StandardScaler\" #conf['scaler_type']\n",
    "exps = conf['box_val_exps']\n",
    "output_cols = conf['output_vars']\n",
    "\n",
    "# Model settings\n",
    "input_size = 9\n",
    "output_size = 2\n",
    "epochs = conf[\"rnn_network\"][\"epochs\"]\n",
    "batch_size = conf[\"rnn_network\"][\"batch_size\"]\n",
    "learning_rate = conf[\"rnn_network\"][\"lr\"]\n",
    "weight_decay = conf[\"rnn_network\"][\"l2_weight\"]\n",
    "n_layers = conf[\"rnn_network\"][\"n_layers\"]\n",
    "hidden_dim = conf[\"rnn_network\"][\"hidden_size\"]\n",
    "rnn_dropout = conf[\"rnn_network\"][\"rnn_dropout\"]\n",
    "hidden_weight = conf[\"rnn_network\"][\"k_decay\"]\n",
    "verbose = conf[\"rnn_network\"][\"verbose\"]\n",
    "lr_patience = 6\n",
    "stopping_patience = 20\n",
    "\n",
    "### Want to be able to reliably test L2 penalty = 0, but the \n",
    "### optuna loguniform prevents this -- so truncate below a certain value\n",
    "weight_decay = weight_decay if weight_decay > 1e-12 else 0.0\n",
    "\n",
    "# Load the data\n",
    "in_train = pd.read_csv(f'/glade/scratch/cbecker/gecko_data/{species}_train_in_agg.csv')\n",
    "out_train = pd.read_csv(f'/glade/scratch/cbecker/gecko_data/{species}_train_out_agg.csv')\n",
    "in_val = pd.read_csv(f'/glade/scratch/cbecker/gecko_data/{species}_val_in_agg.csv')\n",
    "out_val = pd.read_csv(f'/glade/scratch/cbecker/gecko_data/{species}_val_out_agg.csv')\n",
    "\n",
    "in_train = in_train.drop(columns = [x for x in in_train.columns if x == \"Unnamed: 0\"])\n",
    "out_train = out_train.drop(columns = [x for x in out_train.columns if x == \"Unnamed: 0\"])\n",
    "in_val = in_val.drop(columns = [x for x in in_val.columns if x == \"Unnamed: 0\"])\n",
    "out_val = out_val.drop(columns = [x for x in out_val.columns if x == \"Unnamed: 0\"])\n",
    "\n",
    "num_timesteps = in_train['Time [s]'].nunique()\n",
    "\n",
    "# Rescale training and validation / testing data\n",
    "# if scaler_type == \"MinMaxScaler\":\n",
    "#     x_scaler = scalers[scaler_type]((conf['min_scale_range'], conf['max_scale_range']))\n",
    "# else:\n",
    "#     x_scaler = scalers[scaler_type]()\n",
    "\n",
    "x_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "scaled_in_train = x_scaler.fit_transform(in_train.drop(['Time [s]', 'id'], axis=1))\n",
    "scaled_in_val = x_scaler.transform(in_val.drop(['Time [s]', 'id'], axis=1))\n",
    "\n",
    "# y_scaler = get_output_scaler(x_scaler, output_vars, scaler_type, data_range=(\n",
    "#     conf['min_scale_range'], conf['max_scale_range']))\n",
    "\n",
    "scaled_out_train = y_scaler.fit_transform(out_train.drop(['Time [s]', 'id', 'Precursor [ug/m3]'], axis=1))\n",
    "scaled_out_val = y_scaler.transform(out_val.drop(['Time [s]', 'id', 'Precursor [ug/m3]'], axis=1))\n",
    "\n",
    "y = partition_y_output(scaled_out_train, conf[\"dense_network\"]['output_layers'], aggregate_bins)\n",
    "y_val = partition_y_output(scaled_out_val, conf[\"dense_network\"]['output_layers'], aggregate_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time [s]</th>\n",
       "      <th>Precursor [ug/m3]</th>\n",
       "      <th>Gas [ug/m3]</th>\n",
       "      <th>Aerosol [ug_m3]</th>\n",
       "      <th>temperature (K)</th>\n",
       "      <th>solar zenith angle (degree)</th>\n",
       "      <th>pre-existing aerosols (ug/m3)</th>\n",
       "      <th>o3 (ppb)</th>\n",
       "      <th>nox (ppb)</th>\n",
       "      <th>oh (10^6 molec/cm3)</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.423785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>305.065364</td>\n",
       "      <td>52.072802</td>\n",
       "      <td>0.019914</td>\n",
       "      <td>88.598593</td>\n",
       "      <td>1.938279</td>\n",
       "      <td>4.259464</td>\n",
       "      <td>Exp0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301.207794</td>\n",
       "      <td>-1.426829</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>3.058167e-11</td>\n",
       "      <td>304.978044</td>\n",
       "      <td>52.072802</td>\n",
       "      <td>0.019914</td>\n",
       "      <td>88.598593</td>\n",
       "      <td>1.938279</td>\n",
       "      <td>4.259464</td>\n",
       "      <td>Exp0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>601.415588</td>\n",
       "      <td>-1.429875</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>1.193708e-10</td>\n",
       "      <td>304.890766</td>\n",
       "      <td>52.072802</td>\n",
       "      <td>0.019914</td>\n",
       "      <td>88.598593</td>\n",
       "      <td>1.938279</td>\n",
       "      <td>4.259464</td>\n",
       "      <td>Exp0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>901.623352</td>\n",
       "      <td>-1.432922</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>2.814293e-10</td>\n",
       "      <td>304.803571</td>\n",
       "      <td>52.072802</td>\n",
       "      <td>0.019914</td>\n",
       "      <td>88.598593</td>\n",
       "      <td>1.938279</td>\n",
       "      <td>4.259464</td>\n",
       "      <td>Exp0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1201.831177</td>\n",
       "      <td>-1.435969</td>\n",
       "      <td>0.001929</td>\n",
       "      <td>5.148522e-10</td>\n",
       "      <td>304.716502</td>\n",
       "      <td>52.072802</td>\n",
       "      <td>0.019914</td>\n",
       "      <td>88.598593</td>\n",
       "      <td>1.938279</td>\n",
       "      <td>4.259464</td>\n",
       "      <td>Exp0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2302395</th>\n",
       "      <td>430498.968750</td>\n",
       "      <td>-10.631106</td>\n",
       "      <td>0.004719</td>\n",
       "      <td>1.256785e-03</td>\n",
       "      <td>261.094869</td>\n",
       "      <td>28.597493</td>\n",
       "      <td>0.813682</td>\n",
       "      <td>13.364777</td>\n",
       "      <td>2.212563</td>\n",
       "      <td>7.435525</td>\n",
       "      <td>Exp1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2302396</th>\n",
       "      <td>430799.156250</td>\n",
       "      <td>-10.637511</td>\n",
       "      <td>0.004703</td>\n",
       "      <td>1.268518e-03</td>\n",
       "      <td>261.007971</td>\n",
       "      <td>28.597493</td>\n",
       "      <td>0.813682</td>\n",
       "      <td>13.364777</td>\n",
       "      <td>2.212563</td>\n",
       "      <td>7.435525</td>\n",
       "      <td>Exp1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2302397</th>\n",
       "      <td>431099.375000</td>\n",
       "      <td>-10.643919</td>\n",
       "      <td>0.004687</td>\n",
       "      <td>1.280354e-03</td>\n",
       "      <td>260.920898</td>\n",
       "      <td>28.597493</td>\n",
       "      <td>0.813682</td>\n",
       "      <td>13.364777</td>\n",
       "      <td>2.212563</td>\n",
       "      <td>7.435525</td>\n",
       "      <td>Exp1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2302398</th>\n",
       "      <td>431399.593750</td>\n",
       "      <td>-10.650330</td>\n",
       "      <td>0.004672</td>\n",
       "      <td>1.292289e-03</td>\n",
       "      <td>260.833700</td>\n",
       "      <td>28.597493</td>\n",
       "      <td>0.813682</td>\n",
       "      <td>13.364777</td>\n",
       "      <td>2.212563</td>\n",
       "      <td>7.435525</td>\n",
       "      <td>Exp1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2302399</th>\n",
       "      <td>431699.781250</td>\n",
       "      <td>-10.656743</td>\n",
       "      <td>0.004656</td>\n",
       "      <td>1.304317e-03</td>\n",
       "      <td>260.746427</td>\n",
       "      <td>28.597493</td>\n",
       "      <td>0.813682</td>\n",
       "      <td>13.364777</td>\n",
       "      <td>2.212563</td>\n",
       "      <td>7.435525</td>\n",
       "      <td>Exp1599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2302400 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Time [s]  Precursor [ug/m3]  Gas [ug/m3]  Aerosol [ug_m3]  \\\n",
       "0             1.000000          -1.423785     0.000000     0.000000e+00   \n",
       "1           301.207794          -1.426829     0.000494     3.058167e-11   \n",
       "2           601.415588          -1.429875     0.000981     1.193708e-10   \n",
       "3           901.623352          -1.432922     0.001459     2.814293e-10   \n",
       "4          1201.831177          -1.435969     0.001929     5.148522e-10   \n",
       "...                ...                ...          ...              ...   \n",
       "2302395  430498.968750         -10.631106     0.004719     1.256785e-03   \n",
       "2302396  430799.156250         -10.637511     0.004703     1.268518e-03   \n",
       "2302397  431099.375000         -10.643919     0.004687     1.280354e-03   \n",
       "2302398  431399.593750         -10.650330     0.004672     1.292289e-03   \n",
       "2302399  431699.781250         -10.656743     0.004656     1.304317e-03   \n",
       "\n",
       "         temperature (K)  solar zenith angle (degree)  \\\n",
       "0             305.065364                    52.072802   \n",
       "1             304.978044                    52.072802   \n",
       "2             304.890766                    52.072802   \n",
       "3             304.803571                    52.072802   \n",
       "4             304.716502                    52.072802   \n",
       "...                  ...                          ...   \n",
       "2302395       261.094869                    28.597493   \n",
       "2302396       261.007971                    28.597493   \n",
       "2302397       260.920898                    28.597493   \n",
       "2302398       260.833700                    28.597493   \n",
       "2302399       260.746427                    28.597493   \n",
       "\n",
       "         pre-existing aerosols (ug/m3)   o3 (ppb)  nox (ppb)  \\\n",
       "0                             0.019914  88.598593   1.938279   \n",
       "1                             0.019914  88.598593   1.938279   \n",
       "2                             0.019914  88.598593   1.938279   \n",
       "3                             0.019914  88.598593   1.938279   \n",
       "4                             0.019914  88.598593   1.938279   \n",
       "...                                ...        ...        ...   \n",
       "2302395                       0.813682  13.364777   2.212563   \n",
       "2302396                       0.813682  13.364777   2.212563   \n",
       "2302397                       0.813682  13.364777   2.212563   \n",
       "2302398                       0.813682  13.364777   2.212563   \n",
       "2302399                       0.813682  13.364777   2.212563   \n",
       "\n",
       "         oh (10^6 molec/cm3)       id  \n",
       "0                   4.259464     Exp0  \n",
       "1                   4.259464     Exp0  \n",
       "2                   4.259464     Exp0  \n",
       "3                   4.259464     Exp0  \n",
       "4                   4.259464     Exp0  \n",
       "...                      ...      ...  \n",
       "2302395             7.435525  Exp1599  \n",
       "2302396             7.435525  Exp1599  \n",
       "2302397             7.435525  Exp1599  \n",
       "2302398             7.435525  Exp1599  \n",
       "2302399             7.435525  Exp1599  \n",
       "\n",
       "[2302400 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if species == \"apin_O3\":\n",
    "    header = \"/glade/work/schreck/repos/GECKO_OPT/gecko-ml/echo/apin/\"\n",
    "if species == \"dodecane\":\n",
    "    header = \"/glade/work/schreck/repos/GECKO_OPT/gecko-ml/echo/dodecane/\"\n",
    "if species == \"toluene\":\n",
    "    header = \"/glade/work/schreck/repos/GECKO_OPT/gecko-ml/echo/toluene/\"\n",
    "\n",
    "logger.info(f\"Loading training and validation data from cached location {header}\")\n",
    "\n",
    "with open(f\"{header}/train.pkl\", \"rb\") as fid:\n",
    "    train_exps, in_array, env_array = pickle.load(fid)\n",
    "with open(f\"{header}/test.pkl\", \"rb\") as fid:\n",
    "    val_exps, val_in_array, val_env_array = pickle.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUNet(torch.nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    A GRU Neural Network Model that can support arbitrary numbers of hidden layers.\n",
    "\n",
    "    Attributes:\n",
    "        hidden_neurons: int\n",
    "        - Number of neurons in each hidden layer\n",
    "        hidden_layers: int\n",
    "        - Number of hidden layers\n",
    "        drop_prob: float\n",
    "        - proportion of neurons randomly set to 0.\n",
    "        device: str\n",
    "        - CPU or GPU identifier\n",
    "        \n",
    "        gru: torch.nn.Module\n",
    "        - Torch GRU model\n",
    "        fc: torch.nn.Module\n",
    "        - Torch Linear layer for resizing the output of the GRU\n",
    "        relu: torch.nn.Module\n",
    "        - The activation on the GRU output \n",
    "        hidden_model: torch.nn.Module\n",
    "        - Torch Linear layer for the initial hidden state\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 hidden_dim: int,\n",
    "                 n_layers: int, \n",
    "                 drop_prob: float = 0.2): \n",
    "        \n",
    "        super(GRUNet, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dr = drop_prob\n",
    "        self.device = None\n",
    "        \n",
    "        self.gru = None\n",
    "        self.fc = None\n",
    "        self.relu = None\n",
    "        self.hidden_model = None\n",
    "        \n",
    "    def build(self, \n",
    "              input_dim: int, \n",
    "              output_dim: int,\n",
    "              weights_path: str = None) -> None:\n",
    "        \n",
    "        \"\"\"\n",
    "            Build the GRU network \n",
    "        \n",
    "            input_dim: int\n",
    "            - The size of the input\n",
    "            output_dim: int\n",
    "            - The number of prediction targets\n",
    "        \"\"\"\n",
    "        \n",
    "        self.gru = torch.nn.GRU(input_dim, self.hidden_dim, self.n_layers, batch_first=True, dropout=self.dr)\n",
    "        self.fc = torch.nn.Linear(self.hidden_dim, output_dim)\n",
    "        self.relu = torch.nn.LeakyReLU()\n",
    "        self.hidden_model = torch.nn.Linear(input_dim, self.hidden_dim)\n",
    "        \n",
    "        total_params = sum(p.numel() for p in self.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        logger.info(\n",
    "            f\"The model contains {total_params} total parameters, {trainable_params} are trainable\"\n",
    "        )\n",
    "        \n",
    "        if isinstance(weights_path, str):\n",
    "            if os.path.isfile(weights_path):\n",
    "                self.load_weights(weights_path)\n",
    "            else:\n",
    "                logger.info(f\"Failed to load model weights at {weights_path}\")\n",
    "        else:\n",
    "            ## Weights initialization\n",
    "            import torch.nn as nn\n",
    "            import torch.nn.init as init\n",
    "            \n",
    "            def _weights_init(m):\n",
    "                if isinstance(m, nn.Conv2d or nn.Linear):\n",
    "                    init.xavier_normal_(m.weight)\n",
    "                    m.bias.data.zero_()\n",
    "                elif isinstance(m, nn.GRU or nn.LSTM):\n",
    "                    for name, param in m.named_parameters():\n",
    "                        if 'bias' in name:\n",
    "                             nn.init.constant_(param, 0.0)\n",
    "                        elif 'weight_ih' in name:\n",
    "                             nn.init.kaiming_normal_(param)\n",
    "                        elif 'weight_hh' in name:\n",
    "                             nn.init.orthogonal_(param)\n",
    "                elif isinstance(m, nn.BatchNorm2d or nn.BatchNorm1d):\n",
    "                    m.weight.data.fill_(1)\n",
    "                    m.bias.data.zero_()\n",
    "            self.apply(_weights_init)\n",
    "            \n",
    "        \n",
    "    def load_weights(self, weights_path: str) -> None:\n",
    "        \n",
    "        \"\"\"\n",
    "            Loads model weights given a valid weights path\n",
    "            \n",
    "            weights_path: str\n",
    "            - File path to the weights file (.pt)\n",
    "        \"\"\"\n",
    "        logger.info(f\"Loading model weights from {weights_path}\")\n",
    "        \n",
    "        try:\n",
    "            checkpoint = torch.load(\n",
    "                weights_path,\n",
    "                map_location=lambda storage, loc: storage\n",
    "            )\n",
    "            self.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        except Exception as E:\n",
    "            logger.info(\n",
    "                f\"Failed to load model weights at {weights_path} due to error {str(E)}\"\n",
    "            )\n",
    "        \n",
    "        \n",
    "    def forward(self, \n",
    "                x: torch.Tensor, \n",
    "                h: torch.Tensor) -> (torch.Tensor, torch.Tensor):\n",
    "        \n",
    "        \"\"\"\n",
    "            Pass the inputs through the model and return the prediction\n",
    "        \n",
    "            Inputs\n",
    "            x: torch.Tensor\n",
    "            - The input containing precursor, gas, aerosol, and envionmental values\n",
    "            h: torch.Tensor\n",
    "            - The hidden state to the GRU at time t\n",
    "            \n",
    "            Returns\n",
    "            out: torch.Tensor\n",
    "            - The encoded input\n",
    "            h: torch.Tensor\n",
    "            - The hidden state returned by the GRU at time t + 1\n",
    "        \"\"\"\n",
    "        \n",
    "        x = x.unsqueeze(1)\n",
    "        out, h = self.gru(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, \n",
    "                    x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        \"\"\"\n",
    "            Predict a hidden state for the initial input to the model at t = 0\n",
    "        \n",
    "            Inputs\n",
    "            x: torch.Tensor\n",
    "            - The input containing precursor, gas, aerosol, and envionmental values\n",
    "            \n",
    "            Returns: torch.Tensor\n",
    "            - A hidden state corresponding to the initial condition\n",
    "        \"\"\"\n",
    "        \n",
    "        device = self._device() if self.device is None else self.device\n",
    "        hidden = self.hidden_model(x.to(device)).unsqueeze(0)\n",
    "        hidden = torch.cat([hidden.clone() for x in range(self.n_layers)]) if self.n_layers > 1 else hidden\n",
    "        return hidden\n",
    "    \n",
    "    def _device(self) -> str:\n",
    "        \n",
    "        \"\"\"\n",
    "            Set and return the device that the model was placed onto.\n",
    "        \n",
    "            Inputs: None\n",
    "            Returns: str\n",
    "            - Device identifier\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.device = next(self.parameters()).device\n",
    "        return self.device\n",
    "    \n",
    "    def predict(self, \n",
    "                x: np.array, \n",
    "                h: np.array) -> (np.array, np.array):\n",
    "        \n",
    "        \"\"\"\n",
    "            Predict method for running the model in box mode.\n",
    "            Handles converting numpy tensor input to torch\n",
    "            and moving the data to the GPU\n",
    "        \n",
    "            Inputs\n",
    "            x: np.array\n",
    "            - The input containing precursor, gas, aerosol, and envionmental values\n",
    "            h: np.array\n",
    "            - The hidden state to the GRU at time t\n",
    "            \n",
    "            Returns: str\n",
    "            x: np.array\n",
    "            - The encoded input\n",
    "            h: np.array\n",
    "            - The hidden state to the GRU at time t + 1\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        device = self._device() if self.device is None else self.device\n",
    "        with torch.no_grad():\n",
    "            x = torch.from_numpy(x).float().to(device)\n",
    "            x, h = self.forward(x, h)\n",
    "        return x.cpu().detach().numpy(), h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRUNet(hidden_dim, n_layers, rnn_dropout)\n",
    "model.build(input_size, output_size)\n",
    "model = model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train and test losses\n",
    "criterion = torch.nn.SmoothL1Loss() # Huber loss\n",
    "val_criterion = torch.nn.L1Loss()  # Mean absolute error\n",
    "\n",
    "# Load an optimizer\n",
    "logger.info(\"Loading the optimizer\")        \n",
    "        \n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=learning_rate,\n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "\n",
    "# Load an scheduler for the RNN model\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    patience = lr_patience, \n",
    "    verbose = True,\n",
    "    min_lr = 1.0e-13\n",
    ")\n",
    "\n",
    "# lr_scheduler = CosineAnnealingLR_with_Restart(\n",
    "#     optimizer, \n",
    "#     model=model,\n",
    "#     T_max = 4,\n",
    "#     T_mult = 1.5,\n",
    "#     out_dir = \"./\",\n",
    "#     take_snapshot = False,\n",
    "#     eta_min = 1.0e-09\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-1dbf2fb5025c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     train_loss, model, optimizer = rnn_box_train_one_epoch(\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-eb829e7943ae>\u001b[0m in \u001b[0;36mrnn_box_train_one_epoch\u001b[0;34m(model, optimizer, loss_fn, batch_size, exps, num_timesteps, in_array, env_array, hidden_weight, starting_time, grad_clip)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarting_time\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_timesteps\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;31m# Use the last prediction to get the next prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m# static envs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geckonew/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    215\u001b[0m                             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = range(500)\n",
    "results_dict = defaultdict(list)\n",
    "\n",
    "for epoch in epochs:\n",
    "    \n",
    "    train_loss, model, optimizer = rnn_box_train_one_epoch(\n",
    "        model, \n",
    "        optimizer, \n",
    "        criterion, \n",
    "        batch_size, \n",
    "        train_exps, \n",
    "        num_timesteps,\n",
    "        in_array, \n",
    "        env_array,\n",
    "        hidden_weight = hidden_weight\n",
    "    )\n",
    "\n",
    "    val_loss, step_val_loss, _, _ = rnn_box_test(\n",
    "        model, \n",
    "        val_exps, \n",
    "        num_timesteps, \n",
    "        val_in_array, \n",
    "        val_env_array, \n",
    "        y_scaler, \n",
    "        output_cols, \n",
    "        out_val, \n",
    "        starting_index = starting_index\n",
    "    )\n",
    "    \n",
    "    # Get the last learning rate\n",
    "    learning_rate = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Put things into a results dictionary\n",
    "    results_dict[\"epoch\"].append(epoch)\n",
    "    results_dict[\"train_loss\"].append(train_loss)\n",
    "    results_dict[\"val_loss\"].append(val_loss)\n",
    "    results_dict[\"step_val_loss\"].append(step_val_loss)\n",
    "    results_dict[\"lr\"].append(learning_rate)\n",
    "    df = pd.DataFrame.from_dict(results_dict).reset_index()\n",
    "    \n",
    "    # Save the dataframe to disk\n",
    "    df.to_csv(os.path.join(conf[\"output_path\"], \"training_log.csv\"), index = False)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch: {epoch} train_loss: {train_loss:.6f} val_loss: {val_loss:.6f} step_val_loss: {step_val_loss:.6f} lr: {learning_rate}\"\n",
    "    )\n",
    "\n",
    "    # Update the scheduler and anneal the learning rate if required\n",
    "    lr_scheduler.step(val_loss)\n",
    "    # optimizer.param_groups[0]['lr'] = 0.1 * optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Save the model if its the best so far.\n",
    "    if val_loss == min(results_dict[\"val_loss\"]):\n",
    "        state_dict = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': val_loss\n",
    "        }\n",
    "        torch.save(state_dict, os.path.join(conf[\"output_path\"], \"best.pt\"))\n",
    "\n",
    "    # Stop training if we have not improved after X epochs\n",
    "    best_epoch = [i for i,j in enumerate(results_dict[\"val_loss\"]) if j == min(results_dict[\"val_loss\"])][0]\n",
    "    offset = epoch - best_epoch\n",
    "    if offset >= stopping_patience:\n",
    "        break\n",
    "\n",
    "# Select the best loss\n",
    "best_box_mae = min(results_dict[\"val_loss\"])\n",
    "\n",
    "# Return box_mae to optuna\n",
    "results = {\n",
    "    \"box_mae\": best_box_mae\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, step_val_loss, pred, truth = rnn_box_test(\n",
    "        model, \n",
    "        val_exps, \n",
    "        num_timesteps, \n",
    "        val_in_array, \n",
    "        val_env_array, \n",
    "        y_scaler, \n",
    "        output_cols, \n",
    "        out_val, \n",
    "        starting_index = [0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = truth['id'] == 'Exp1600'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time [s]</th>\n",
       "      <th>Precursor [ug/m3]</th>\n",
       "      <th>Gas [ug/m3]</th>\n",
       "      <th>Aerosol [ug_m3]</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301.207794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>1.218404e-05</td>\n",
       "      <td>Exp1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>601.415588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>1.096865e-05</td>\n",
       "      <td>Exp1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>901.623352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>9.938850e-06</td>\n",
       "      <td>Exp1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1201.831177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>9.209213e-06</td>\n",
       "      <td>Exp1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1502.038940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>8.696833e-06</td>\n",
       "      <td>Exp1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>430799.156250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>2.917847e-07</td>\n",
       "      <td>Exp1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>431099.375000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>3.978917e-07</td>\n",
       "      <td>Exp1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>431399.593750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>4.884660e-07</td>\n",
       "      <td>Exp1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>431699.781250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>5.659281e-07</td>\n",
       "      <td>Exp1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>432000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>6.441972e-07</td>\n",
       "      <td>Exp1600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1439 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time [s]  Precursor [ug/m3]  Gas [ug/m3]  Aerosol [ug_m3]       id\n",
       "0        301.207794                NaN     0.000756     1.218404e-05  Exp1600\n",
       "1        601.415588                NaN     0.000758     1.096865e-05  Exp1600\n",
       "2        901.623352                NaN     0.000751     9.938850e-06  Exp1600\n",
       "3       1201.831177                NaN     0.000738     9.209213e-06  Exp1600\n",
       "4       1502.038940                NaN     0.000728     8.696833e-06  Exp1600\n",
       "...             ...                ...          ...              ...      ...\n",
       "1434  430799.156250                NaN     0.000723     2.917847e-07  Exp1600\n",
       "1435  431099.375000                NaN     0.000723     3.978917e-07  Exp1600\n",
       "1436  431399.593750                NaN     0.000723     4.884660e-07  Exp1600\n",
       "1437  431699.781250                NaN     0.000724     5.659281e-07  Exp1600\n",
       "1438  432000.000000                NaN     0.000724     6.441972e-07  Exp1600\n",
       "\n",
       "[1439 rows x 5 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time [s]</th>\n",
       "      <th>Precursor [ug/m3]</th>\n",
       "      <th>Gas [ug/m3]</th>\n",
       "      <th>Aerosol [ug_m3]</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301.207794</td>\n",
       "      <td>3.721285e-02</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>Exp1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>601.415588</td>\n",
       "      <td>3.674244e-02</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>Exp1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>901.623352</td>\n",
       "      <td>3.627777e-02</td>\n",
       "      <td>0.002110</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>Exp1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1201.831177</td>\n",
       "      <td>3.581876e-02</td>\n",
       "      <td>0.002777</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>Exp1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1502.038940</td>\n",
       "      <td>3.536536e-02</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>Exp1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>430799.156250</td>\n",
       "      <td>4.460552e-10</td>\n",
       "      <td>0.009388</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>Exp1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>431099.375000</td>\n",
       "      <td>4.404294e-10</td>\n",
       "      <td>0.009367</td>\n",
       "      <td>0.004252</td>\n",
       "      <td>Exp1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>431399.593750</td>\n",
       "      <td>4.348721e-10</td>\n",
       "      <td>0.009345</td>\n",
       "      <td>0.004264</td>\n",
       "      <td>Exp1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>431699.781250</td>\n",
       "      <td>4.293824e-10</td>\n",
       "      <td>0.009324</td>\n",
       "      <td>0.004275</td>\n",
       "      <td>Exp1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>432000.000000</td>\n",
       "      <td>4.239595e-10</td>\n",
       "      <td>0.009303</td>\n",
       "      <td>0.004287</td>\n",
       "      <td>Exp1600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1439 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time [s]  Precursor [ug/m3]  Gas [ug/m3]  Aerosol [ug_m3]       id\n",
       "0        301.207794       3.721285e-02     0.000708         0.000003  Exp1600\n",
       "1        601.415588       3.674244e-02     0.001421         0.000009  Exp1600\n",
       "2        901.623352       3.627777e-02     0.002110         0.000016  Exp1600\n",
       "3       1201.831177       3.581876e-02     0.002777         0.000026  Exp1600\n",
       "4       1502.038940       3.536536e-02     0.003423         0.000038  Exp1600\n",
       "...             ...                ...          ...              ...      ...\n",
       "1434  430799.156250       4.460552e-10     0.009388         0.004241  Exp1600\n",
       "1435  431099.375000       4.404294e-10     0.009367         0.004252  Exp1600\n",
       "1436  431399.593750       4.348721e-10     0.009345         0.004264  Exp1600\n",
       "1437  431699.781250       4.293824e-10     0.009324         0.004275  Exp1600\n",
       "1438  432000.000000       4.239595e-10     0.009303         0.004287  Exp1600\n",
       "\n",
       "[1439 rows x 5 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(truth[a]['Time [s]'], truth[a]['Gas [ug/m3]'])\n",
    "plt.plot(truth[a]['Time [s]'], pred[a]['Gas [ug/m3]'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
