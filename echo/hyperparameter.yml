log:
  save_path: "/glade/work/schreck/repos/gecko-ml/scripts/schreck/echo/test/log.txt"

slurm:
  jobs: 15
#   kernel: "ncar_pylib /glade/work/keelyl/ncar_20200417"
  bash: ["module load cuda/11 cudnn"]
  batch:
    account: "NAML0001"
    gres: "gpu:v100:1"
    mem: "64G"
    x: "casper36"
    n: 8
    t: "24:00:00"
    J: "gecko_opt"
    o: "hyper_opt.out"
    e: "hyper_opt.err"
    
optuna:
  study_name: "gecko"
  storage: "sqlite:////glade/work/schreck/repos/gecko-ml/scripts/schreck/echo/test/gecko.db"
  reload: 0
  objective: "/glade/work/schreck/repos/gecko-ml/scripts/schreck/echo/objective.py"
  direction: "minimize"
  metric: "box_mae"
  n_trials: 999
  gpu: True
  save_path: '/glade/work/schreck/repos/gecko-ml/scripts/schreck/echo/test'
  sampler:
    type: "TPESampler"
    n_startup_trials: 50
  parameters:
#     dense_network:hidden_layers:
#       type: "int"
#       settings:
#         name: "hidden_layers"
#         low: 1
#         high: 2
    dense_network:hidden_neurons:
      type: "int"
      settings:
        name: "hidden_neurons"
        low: 50
        high: 5000
    dense_network:lr:
      type: "loguniform"
      settings:
        name: "lr"
        low: 0.00000001
        high: 0.001
    dense_network:l1_weight:
      type: "loguniform"
      settings:
        name: "l1_weight"
        low: 1.0e-12
        high: 0.1
    dense_network:l2_weight:
      type: "loguniform"
      settings:
        name: "l2_weight"
        low: 1.0e-12
        high: 0.1
#     dense_network:batch_size:
#       type: "int"
#       settings: 
#         name: "batch_size"
#         low: 128
#         high: 16384
#     dense_network:dropout_alpha:
#       type: "float"
#       settings: 
#         name: "dropout_alpha"
#         low: 0.0
#         high: 0.9
#     dense_network:activation:
#       type: "categorical"
#       settings:
#         name: "activation"
#         choices: ["relu", "leaky", "selu", "elu", "prelu"]
#     dense_network:loss:
#       type: "categorical"
#       settings:
#         name: "loss"
#         choices: [["Xsigmoid"], ["Xtanh"], ["mae"], ["mse"], ["log_cosh"], ["mean_squared_logarithmic_error"], ["poisson"], ["huber"]]
#     dense_network:optimizer:
#       type: "categorical"
#       settings: 
#         name: "optimizer"
#         choices: ["adam"]
#     scaler_type:
#       type: "categorical"
#       settings:
#         name: "scaler_type"
#         choices: ["StandardScaler"]
#     dense_network:output_activation:
#       type: "categorical"
#       settings:
#         name: "output_activation"
#         choices: ["linear", "lambda:100", "lambda:10", "lambda:1", "lambda:0.1", "lambda:0.01"]
        
#[["mae"], ["mse"], ["log_cosh"], ["mean_squared_logarithmic_error"], ["poisson"], ["huber"], ["Xsigmoid"], ["Xtanh"]]
        
        
#     dense_network:custom_activation_decay_rate:
#       type: "loguniform"
#       settings:
#         name: "custom_activation_decay_rate"
#         low: 1.0e-03
#         high: 1000

#     dense_network:epsilon:
#       type: "loguniform"
#       settings:
#         name: "epsilon"
#         low: 0.000000001
#         high: 0.1
#     dense_network:epochs:
#       type: "int"
#       settings:
#         name: "epochs"
#         low: 500
#         high: 5000
#     precursor_weight:
#       type: "loguniform"
#       settings:
#         name: "precursor_weight"
#         low: 0.1
#         high: 100
#     gas_weight:
#       type: "loguniform"
#       settings:
#         name: "gas_weight"
#         low: 0.1
#         high: 100
#     aerosol_weight:
#       type: "loguniform"
#       settings:
#         name: "aerosol_weight"
#         low: 0.1
#         high: 100