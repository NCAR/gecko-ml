{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_profiling\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "import yaml\n",
    "import shap\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, yaml, keras\n",
    "import multiprocessing as mp\n",
    "#sys.path.insert(0, '/glade/work/cbecker/gecko-ml/')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import copy\n",
    "import optuna\n",
    "import logging\n",
    "import traceback\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from geckoml.models import DenseNeuralNetwork\n",
    "from geckoml.data import *\n",
    "#from geckoml.box import *\n",
    "from geckoml.metrics import *\n",
    "#from geckoml.callbacks import *\n",
    "\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GaussianNoise, Activation, \\\n",
    "    Concatenate, BatchNormalization, LSTM, Conv1D, AveragePooling1D, MaxPooling1D, LeakyReLU, PReLU, ELU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a tqdm that works with notebooks when using tqdm more than once \n",
    "from tqdm import tqdm as tqdm_base\n",
    "def tqdm(*args, **kwargs):\n",
    "    if hasattr(tqdm_base, '_instances'):\n",
    "        for instance in list(tqdm_base._instances):\n",
    "            tqdm_base._decr_instances(instance)\n",
    "    return tqdm_base(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_val(mod, exps, num_timesteps, in_array, env_array, y_scaler, output_cols, out_val):\n",
    "    \n",
    "    # use initial condition @ t = 0 and get the first prediction\n",
    "    pred_array = np.empty((len(exps), 1439, 3))\n",
    "    pred = mod.predict(in_array[:, 0, :])\n",
    "    pred_array[:, 0, :] = pred\n",
    "\n",
    "    # use the first prediction to get the next, and so on for num_timesteps\n",
    "    for i in tqdm(range(1, num_timesteps)):\n",
    "        temperature = in_array[:, i, 3:4]\n",
    "        static_env = env_array[:, -5:]\n",
    "        new_input = np.block([pred, temperature, static_env])\n",
    "        pred = mod(new_input, training=False)\n",
    "        pred_array[:, i, :] = pred\n",
    "\n",
    "    # loop over the batch to fill up results dict\n",
    "    results_dict = {}\n",
    "    for k, exp in enumerate(exps):\n",
    "        results_dict[exp] = pd.DataFrame(y_scaler.inverse_transform(pred_array[k]), columns=output_cols[1:-1])\n",
    "        results_dict[exp]['id'] = exp\n",
    "        results_dict[exp]['Time [s]'] = out_val['Time [s]'].unique()\n",
    "        results_dict[exp] = results_dict[exp].reindex(output_cols, axis=1)\n",
    "\n",
    "    preds = pd.concat(results_dict.values())\n",
    "    truth = out_val.loc[out_val['id'].isin(exps)]\n",
    "    truth = truth.sort_values(['id', 'Time [s]']).reset_index(drop=True)\n",
    "    preds = preds.sort_values(['id', 'Time [s]']).reset_index(drop=True)\n",
    "    box_mae = mean_absolute_error(preds.iloc[:, 2:-1], truth.iloc[:, 2:-1])\n",
    "    \n",
    "    return box_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_val_shap(mod, exps, num_timesteps, in_array, env_array, y_scaler, output_cols, out_val):\n",
    "    \n",
    "    # use initial condition @ t = 0 and get the first prediction\n",
    "    pred_array = np.empty((len(exps), 1439, 3))\n",
    "    input_array = np.empty((len(exps), 1439, 9))\n",
    "    pred = mod.predict(in_array[:, 0, :])\n",
    "    input_array[:, 0, :] = in_array[:, 0, :]\n",
    "    pred_array[:, 0, :] = pred\n",
    "\n",
    "    # use the first prediction to get the next, and so on for num_timesteps\n",
    "    for i in tqdm(range(1, num_timesteps)):\n",
    "        temperature = in_array[:, i, 3:4]\n",
    "        static_env = env_array[:, -5:]\n",
    "        new_input = np.block([pred, temperature, static_env])\n",
    "        pred = mod(new_input, training=False)\n",
    "        pred_array[:, i, :] = pred\n",
    "        input_array[:, i, :] = new_input\n",
    "    \n",
    "    return input_array, pred_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"toluene_model_config.yml\") as config_file:\n",
    "    conf = yaml.load(config_file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(5999)\n",
    "\n",
    "scalers = {\"MinMaxScaler\": MinMaxScaler,\n",
    "           \"StandardScaler\": StandardScaler}\n",
    "\n",
    "species = conf['species']\n",
    "dir_path = conf['dir_path']\n",
    "summary_file = conf['summary_file']\n",
    "aggregate_bins = conf['aggregate_bins']\n",
    "bin_prefix = conf['bin_prefix']\n",
    "input_vars = conf['input_vars']\n",
    "output_vars = conf['output_vars']\n",
    "scaler_type = conf['scaler_type']\n",
    "exps = conf['box_val_exps']\n",
    "output_cols = conf['output_vars']\n",
    "\n",
    "# Load the data\n",
    "in_train = pd.read_csv(f'/glade/scratch/cbecker/gecko_data/{species}_train_in_agg.csv')\n",
    "out_train = pd.read_csv(f'/glade/scratch/cbecker/gecko_data/{species}_train_out_agg.csv')\n",
    "in_val = pd.read_csv(f'/glade/scratch/cbecker/gecko_data/{species}_val_in_agg.csv')\n",
    "out_val = pd.read_csv(f'/glade/scratch/cbecker/gecko_data/{species}_val_out_agg.csv')\n",
    "        \n",
    "# in_train = pd.read_csv('/glade/scratch/cbecker/gecko_data/apin_O3_train_in_agg.csv')\n",
    "# out_train = pd.read_csv('/glade/scratch/cbecker/gecko_data/apin_O3_train_out_agg.csv')\n",
    "# in_val = pd.read_csv('/glade/scratch/cbecker/gecko_data/apin_O3_val_in_agg.csv')\n",
    "# out_val = pd.read_csv('/glade/scratch/cbecker/gecko_data/apin_O3_val_out_agg.csv')\n",
    "\n",
    "num_timesteps = in_train['Time [s]'].nunique()\n",
    "\n",
    "# Rescale training and validation / testing data\n",
    "if scaler_type == \"MinMaxScaler\":\n",
    "    x_scaler = scalers[scaler_type]((conf['min_scale_range'], conf['max_scale_range']))\n",
    "else:\n",
    "    x_scaler = scalers[scaler_type]()\n",
    "scaled_in_train = x_scaler.fit_transform(in_train.drop(['Time [s]', 'id'], axis=1))\n",
    "scaled_in_val = x_scaler.transform(in_val.drop(['Time [s]', 'id'], axis=1))\n",
    "\n",
    "y_scaler = get_output_scaler(x_scaler, output_vars, scaler_type, data_range=(\n",
    "    conf['min_scale_range'], conf['max_scale_range']))\n",
    "scaled_out_train = y_scaler.transform(out_train.drop(['Time [s]', 'id'], axis=1))\n",
    "scaled_out_val = y_scaler.transform(out_val.drop(['Time [s]', 'id'], axis=1))\n",
    "\n",
    "y = partition_y_output(scaled_out_train, conf[\"dense_network\"]['output_layers'], aggregate_bins)\n",
    "y_val = partition_y_output(scaled_out_val, conf[\"dense_network\"]['output_layers'], aggregate_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1600/1600 [00:26<00:00, 61.19it/s]\n"
     ]
    }
   ],
   "source": [
    "def work(exp):\n",
    "    in_data = x_scaler.transform(in_train[in_train['id'] == exp].iloc[:, 1:-1])\n",
    "    env_conds = in_data[0, -6:]\n",
    "    return (np.expand_dims(in_data, axis=0), np.expand_dims(env_conds, axis=0))\n",
    "\n",
    "train_exps = list(in_train['id'].unique())\n",
    "pool = mp.Pool(processes=8)\n",
    "in_array, env_array = zip(*[result for result in tqdm(pool.imap(work, train_exps), total = len(train_exps))])\n",
    "pool.close()\n",
    "\n",
    "in_array = np.concatenate(in_array) # (num_experiments, num_timesteps, outputs)\n",
    "env_array = np.concatenate(env_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 369.14it/s]\n"
     ]
    }
   ],
   "source": [
    "def work(exp):\n",
    "    in_data = x_scaler.transform(in_val[in_val['id'] == exp].iloc[:, 1:-1])\n",
    "    env_conds = in_data[0, -6:]\n",
    "    return (np.expand_dims(in_data, axis=0), np.expand_dims(env_conds, axis=0))\n",
    "\n",
    "val_exps = list(in_val['id'].unique())\n",
    "pool = mp.Pool(processes=8)\n",
    "val_in_array, val_env_array = zip(*[result for result in tqdm(pool.imap(work, val_exps), total = len(val_exps))])\n",
    "pool.close()\n",
    "\n",
    "val_in_array = np.concatenate(val_in_array) # (num_experiments, num_timesteps, outputs)\n",
    "val_env_array = np.concatenate(val_env_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "\n",
    "#mod = DenseNeuralNetwork(**conf[\"dense_network\"])\n",
    "#inputs = scaled_in_train.shape[1]\n",
    "#outputs = [i.shape[-1] for i in y]\n",
    "#mod.build_neural_network(inputs, outputs)\n",
    "#mod.model.load_weights(f\"/glade/work/schreck/repos/gecko-ml/scripts/schreck/echo/best_500.h5\")\n",
    "#model = mod.model\n",
    "\n",
    "model = tf.keras.models.load_model('/glade/work/keelyl/geckonew/gecko-ml/toluene_agg_runs_unvaried/models_4_27/toluene_dnn_1_15/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1438/1438 [00:02<00:00, 582.14it/s]\n"
     ]
    }
   ],
   "source": [
    "box_mae = box_val(\n",
    "    model, \n",
    "    val_exps, \n",
    "    num_timesteps, \n",
    "    val_in_array, \n",
    "    val_env_array, \n",
    "    y_scaler, \n",
    "    output_cols, \n",
    "    out_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006812136084287767"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the validation box input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x, _y = box_val_shap(\n",
    "    model, \n",
    "    val_exps, \n",
    "    num_timesteps, \n",
    "    val_in_array, \n",
    "    val_env_array, \n",
    "    y_scaler, \n",
    "    output_cols, \n",
    "    out_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = shap.maskers.Independent(scaled_in_train[np.random.choice(scaled_in_train.shape[0], 1000, replace=False)])\n",
    "explainer = shap.Explainer(model, background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "    \n",
    "    def __init__(self, x, exp_id):\n",
    "        self.x = x\n",
    "        self.id = exp_id\n",
    "    \n",
    "    def work(self, t):\n",
    "        return explainer(np.expand_dims(self.x[self.id][t], axis=0)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(experiment_id, actual_id):\n",
    "    \n",
    "    exp = Experiment(_x, experiment_id)\n",
    "    shap_results = [exp.work(t) for t in tqdm(range(_x.shape[1]))]\n",
    "    \n",
    "    pre = np.vstack([i.squeeze(0)[:,0] for i in shap_results])\n",
    "    gas = np.vstack([i.squeeze(0)[:,1] for i in shap_results])\n",
    "    air = np.vstack([i.squeeze(0)[:,2] for i in shap_results])\n",
    "    \n",
    "    plt.figure(figsize=(7,14))\n",
    "\n",
    "    plt.subplot(311)\n",
    "    leg = ['gas', 'aerosol', 'temperature', 'sza', 'pre-existing aerosol', 'ozone', 'nox', 'OH']\n",
    "    for i in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "        plt.plot(range(1439), pre[:, i])\n",
    "    plt.ylabel(\"Precursor SHAP\", fontsize = 14)\n",
    "    plt.legend(leg, fontsize = 12, ncol=2, loc = 'best')\n",
    "\n",
    "\n",
    "    plt.subplot(312)\n",
    "    leg = ['precursor', 'aerosol', 'temperature', 'sza', 'pre-existing aero', 'ozone', 'nox', 'OH']\n",
    "    for i in [0, 2, 3, 4, 5, 6, 7, 8]:\n",
    "        plt.plot(range(1439), gas[:, i])\n",
    "    plt.ylabel(\"Gas SHAP\", fontsize = 14)\n",
    "    plt.legend(leg, fontsize = 12, ncol=2, loc = 'best')\n",
    "\n",
    "    plt.subplot(313)\n",
    "    leg = ['precursor', 'gas', 'temperature', 'sza', 'pre-existing aero', 'ozone', 'nox', 'OH']\n",
    "    for i in [0, 1, 3, 4, 5, 6, 7, 8]:\n",
    "        plt.plot(range(1439), air[:, i])\n",
    "    plt.ylabel(\"Aerosol SHAP\", fontsize = 14)\n",
    "    plt.legend(leg, fontsize = 12, ncol=2, loc = 'best')\n",
    "\n",
    "    plt.xlabel(\"Time (s)\", fontsize = 14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(f\"images/{species}/validation_{actual_id}.png\")\n",
    "    np.save(f\"images/{species}/validation_{actual_id}_pre.npy\", pre)\n",
    "    np.save(f\"images/{species}/validation_{actual_id}_gas.npy\", gas)\n",
    "    np.save(f\"images/{species}/validation_{actual_id}_aero.npy\", air)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_experiments = {k: n for k,n in enumerate(list(in_val['id'].unique()))}\n",
    "val_experiments = sorted(val_experiments.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (idx, exp) in val_experiments:\n",
    "    results(idx, exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next compute average |SHAP| values across the time-steps. This will let us compare experiments together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: None. Using widget instead.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_exps = sorted([x.split(\"_\")[1] for x in glob.glob(f\"images/{species}/validation_*_pre.npy\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = {\"pre\": [], \"gas\": [], \"air\": []}\n",
    "deviations = {\"pre\": [], \"gas\": [], \"air\": []}\n",
    "for exp in val_exps:\n",
    "    pre = np.load(f\"images/{species}/validation_{exp}_pre.npy\")\n",
    "    gas = np.load(f\"images/{species}/validation_{exp}_gas.npy\")\n",
    "    air = np.load(f\"images/{species}/validation_{exp}_aero.npy\")\n",
    "    \n",
    "    pre_ave = np.mean(np.abs(pre), axis = 0)\n",
    "    gas_ave = np.mean(np.abs(gas), axis = 0)\n",
    "    air_ave = np.mean(np.abs(air), axis = 0)\n",
    "    \n",
    "    averages[\"pre\"].append(pre_ave)\n",
    "    averages[\"gas\"].append(gas_ave)\n",
    "    averages[\"air\"].append(air_ave)\n",
    "    \n",
    "    #pre_std = np.mean(pre, axis = 0)\n",
    "    #gas_std = np.mean(gas, axis = 0)\n",
    "    #air_std = np.mean(air, axis = 0)\n",
    "    \n",
    "averages[\"pre\"] = np.vstack(averages[\"pre\"])\n",
    "averages[\"gas\"] = np.vstack(averages[\"gas\"])\n",
    "averages[\"air\"] = np.vstack(averages[\"air\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198, 9)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averages[\"air\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmean = [np.mean(averages[\"pre\"][:,i]) for i in range(9)]\n",
    "pstd = [stats.sem(averages[\"pre\"][:,i]) for i in range(9)]\n",
    "\n",
    "gmean = [np.mean(averages[\"gas\"][:,i]) for i in range(9)]\n",
    "gstd = [stats.sem(averages[\"gas\"][:,i]) for i in range(9)]\n",
    "\n",
    "amean = [np.mean(averages[\"air\"][:,i]) for i in range(9)]\n",
    "astd = [stats.sem(averages[\"air\"][:,i]) for i in range(9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8410168776714115ad0f65399762000f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.subplot(111)\n",
    "plt.errorbar(range(9), pmean, yerr = pstd)\n",
    "plt.errorbar(range(9), gmean, yerr = gstd)\n",
    "plt.errorbar(range(9), amean, yerr = astd)\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.ylabel(\"Toluene <|SHAP|>\")\n",
    "#plt.xlabel(\"Feature\")\n",
    "\n",
    "labels = ['precursor', 'gas', 'aerosol', 'temperature', 'sza', 'pre-existing aerosol', 'ozone', 'nox', 'OH']\n",
    "plt.xticks(range(9), labels, rotation=45)\n",
    "\n",
    "plt.legend([\"Precursor\", \"Gas\", \"Aerosol\"], loc = \"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"toluene.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e7ba9c78cec4f2798489fd3c600881f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,14))\n",
    "\n",
    "plt.subplot(311)\n",
    "leg = ['gas', 'aerosol', 'temperature', 'sza', 'pre-existing aerosol', 'ozone', 'nox', 'OH']\n",
    "for i in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "    plt.hist(averages[\"pre\"][:,i], alpha = 0.9)\n",
    "plt.ylabel(\"Precursor SHAP\", fontsize = 14)\n",
    "plt.legend(leg, fontsize = 12, ncol=2, loc = 'best')\n",
    "\n",
    "plt.subplot(312)\n",
    "leg = ['precursor', 'aerosol', 'temperature', 'sza', 'pre-existing aero', 'ozone', 'nox', 'OH']\n",
    "for i in [0, 2, 3, 4, 5, 6, 7, 8]:\n",
    "    plt.hist(averages[\"gas\"][:,i], alpha = 0.9)\n",
    "plt.ylabel(\"Gas SHAP\", fontsize = 14)\n",
    "plt.legend(leg, fontsize = 12, ncol=2, loc = 'best')\n",
    "\n",
    "plt.subplot(313)\n",
    "leg = ['precursor', 'gas', 'temperature', 'sza', 'pre-existing aero', 'ozone', 'nox', 'OH']\n",
    "for i in [0, 1, 3, 4, 5, 6, 7, 8]:\n",
    "    plt.hist(averages[\"air\"][:,i], alpha = 0.9)\n",
    "plt.ylabel(\"Aerosol SHAP\", fontsize = 14)\n",
    "plt.legend(leg, fontsize = 12, ncol=2, loc = 'best')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"toluene_histogram.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
